{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "# 01. Data Analysis & Visualisation\n",
    "_______________\n",
    "In this lab we will perform an exploratory data analysis, visualization, and classification tasks on a spam filtering dataset. We will finally make use of all the libraries covered earlier, as well as a new one, `scikit-learn`, used for machine learning. Throughout this lab there will be references to new methods, so dont get confused and refer to the documentation + ctrl-f (find) if something seems unclear:\n",
    "* [Scikit-learn API documentation](http://scikit-learn.org/stable/modules/classes.html) \n",
    "* [Seaborn API documentation](https://seaborn.github.io/api.html)\n",
    "* [Matplotlib Pyplot documentation](http://matplotlib.org/1.5.3/api/pyplot_summary.html)\n",
    "* [Pandas API documentation](http://pandas.pydata.org/pandas-docs/stable/api.html)\n",
    "* [Numpy documentation](http://docs.scipy.org/doc/numpy/reference/)\n",
    "\n",
    "`N.B.` Most of the material was adopted from the UoE's Introductory Applied Machine Learning [INFR10069](http://www.drps.ed.ac.uk/17-18/dpt/cxinfr10069.htm) course labs created by James Overs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%matplotlib inline` command is a special ipython [built in magic command](http://ipython.readthedocs.io/en/stable/interactive/magics.html) which forces the matplotlib plots to be rendered within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spambase dataset\n",
    "The [Spambase](http://archive.ics.uci.edu/ml/datasets/Spambase) dataset consists of tagged emails from a single email account. You should read through the description available for this data to get a feel for what you're dealing with. We have downloaded the dataset for you.\n",
    "\n",
    "You will find the dataset located at `./datasets/spambase.csv` (the `datasets` directory is adjacent to this file). Execute the cell below to load the csv into in a pandas DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                        61.0   \n",
       "1                       5.114                       101.0   \n",
       "2                       9.821                       485.0   \n",
       "3                       3.537                        40.0   \n",
       "4                       3.537                        40.0   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                     278.0      1.0  \n",
       "1                    1028.0      1.0  \n",
       "2                    2259.0      1.0  \n",
       "3                     191.0      1.0  \n",
       "4                     191.0      1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'spambase.csv')\n",
    "spambase = pd.read_csv(data_path, delimiter = ',')\n",
    "\n",
    "spambase.head(5) # Display the 5 first rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "58\n",
      "word_freq_make                  0.104553\n",
      "word_freq_address               0.213015\n",
      "word_freq_all                   0.280656\n",
      "word_freq_3d                    0.065425\n",
      "word_freq_our                   0.312223\n",
      "word_freq_over                  0.095901\n",
      "word_freq_remove                0.114208\n",
      "word_freq_internet              0.105295\n",
      "word_freq_order                 0.090067\n",
      "word_freq_mail                  0.239413\n",
      "word_freq_receive               0.059824\n",
      "word_freq_will                  0.541702\n",
      "word_freq_people                0.093930\n",
      "word_freq_report                0.058626\n",
      "word_freq_addresses             0.049205\n",
      "word_freq_free                  0.248848\n",
      "word_freq_business              0.142586\n",
      "word_freq_email                 0.184745\n",
      "word_freq_you                   1.662100\n",
      "word_freq_credit                0.085577\n",
      "word_freq_your                  0.809761\n",
      "word_freq_font                  0.121202\n",
      "word_freq_000                   0.101645\n",
      "word_freq_money                 0.094269\n",
      "word_freq_hp                    0.549504\n",
      "word_freq_hpl                   0.265384\n",
      "word_freq_george                0.767305\n",
      "word_freq_650                   0.124845\n",
      "word_freq_lab                   0.098915\n",
      "word_freq_labs                  0.102852\n",
      "word_freq_telnet                0.064753\n",
      "word_freq_857                   0.047048\n",
      "word_freq_data                  0.097229\n",
      "word_freq_415                   0.047835\n",
      "word_freq_85                    0.105412\n",
      "word_freq_technology            0.097477\n",
      "word_freq_1999                  0.136953\n",
      "word_freq_parts                 0.013201\n",
      "word_freq_pm                    0.078629\n",
      "word_freq_direct                0.064834\n",
      "word_freq_cs                    0.043667\n",
      "word_freq_meeting               0.132339\n",
      "word_freq_original              0.046099\n",
      "word_freq_project               0.079196\n",
      "word_freq_re                    0.301224\n",
      "word_freq_edu                   0.179824\n",
      "word_freq_table                 0.005444\n",
      "word_freq_conference            0.031869\n",
      "char_freq_;                     0.038575\n",
      "char_freq_(                     0.139030\n",
      "char_freq_[                     0.016976\n",
      "char_freq_!                     0.269071\n",
      "char_freq_$                     0.075811\n",
      "char_freq_#                     0.044238\n",
      "capital_run_length_average      5.191515\n",
      "capital_run_length_longest     52.172789\n",
      "capital_run_length_total      283.289285\n",
      "is_spam                         0.394045\n",
      "dtype: float64\n",
      "word_freq_make                  0.305358\n",
      "word_freq_address               1.290575\n",
      "word_freq_all                   0.504143\n",
      "word_freq_3d                    1.395151\n",
      "word_freq_our                   0.672513\n",
      "word_freq_over                  0.273824\n",
      "word_freq_remove                0.391441\n",
      "word_freq_internet              0.401071\n",
      "word_freq_order                 0.278616\n",
      "word_freq_mail                  0.644755\n",
      "word_freq_receive               0.201545\n",
      "word_freq_will                  0.861698\n",
      "word_freq_people                0.301036\n",
      "word_freq_report                0.335184\n",
      "word_freq_addresses             0.258843\n",
      "word_freq_free                  0.825792\n",
      "word_freq_business              0.444055\n",
      "word_freq_email                 0.531122\n",
      "word_freq_you                   1.775481\n",
      "word_freq_credit                0.509767\n",
      "word_freq_your                  1.200810\n",
      "word_freq_font                  1.025756\n",
      "word_freq_000                   0.350286\n",
      "word_freq_money                 0.442636\n",
      "word_freq_hp                    1.671349\n",
      "word_freq_hpl                   0.886955\n",
      "word_freq_george                3.367292\n",
      "word_freq_650                   0.538576\n",
      "word_freq_lab                   0.593327\n",
      "word_freq_labs                  0.456682\n",
      "word_freq_telnet                0.403393\n",
      "word_freq_857                   0.328559\n",
      "word_freq_data                  0.555907\n",
      "word_freq_415                   0.329445\n",
      "word_freq_85                    0.532260\n",
      "word_freq_technology            0.402623\n",
      "word_freq_1999                  0.423451\n",
      "word_freq_parts                 0.220651\n",
      "word_freq_pm                    0.434672\n",
      "word_freq_direct                0.349916\n",
      "word_freq_cs                    0.361205\n",
      "word_freq_meeting               0.766819\n",
      "word_freq_original              0.223812\n",
      "word_freq_project               0.621976\n",
      "word_freq_re                    1.011687\n",
      "word_freq_edu                   0.911119\n",
      "word_freq_table                 0.076274\n",
      "word_freq_conference            0.285735\n",
      "char_freq_;                     0.243471\n",
      "char_freq_(                     0.270355\n",
      "char_freq_[                     0.109394\n",
      "char_freq_!                     0.815672\n",
      "char_freq_$                     0.245882\n",
      "char_freq_#                     0.429342\n",
      "capital_run_length_average     31.729449\n",
      "capital_run_length_longest    194.891310\n",
      "capital_run_length_total      606.347851\n",
      "is_spam                         0.488698\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display the number of observations (i.e. number of rows).\n",
    "print (spambase.shape[0])\n",
    "\n",
    "# Display the number of attributes in the dataset (i.e. number of columns).\n",
    "print (spambase.shape[1]) \n",
    "\n",
    "# Display the mean and standard deviation of each attribute.\n",
    "print (spambase.mean())\n",
    "print (spambase.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000   \n",
       "max       4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total      is_spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to *remove* some of the attributes from our data. There are various reasons for wanting to do so, for instance we might think that these are not relevant to the task we want to perform (i.e. e-mail classification) or they might have been contaminated with noise during the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Delete the `capital_run_length_average`, `capital_run_length_longest` and  `capital_run_length_total` attributes. *Hint*: You should make use of the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method. \n",
    "\n",
    "*`Tip`*: some pandas methods have the argument `inplace` which you can use to determine whether they alter the object they are called upon and return nothing, or return a new object. This is particularly useful if you are dealing with huge datasets where you would typically want to operate `inplace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase.drop(['capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Display the new number of attributes. Does it look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print (spambase.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining attributes represent relative frequencies of various important words and characters in emails. This is true for all attributes except `is_spam` which represents whether the e-mail was annotated as spam or not. So each e-mail is represented by a 55 dimensional vector representing whether or not a particular word exists in an e-mail. This is the so called [bag of words](http://en.wikipedia.org/wiki/Bag_of_words_model) representation and is clearly a very crude approximation since it does not take into account the order of the words in the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a feeling of the distribution of ham (i.e. valid) vs. spam emails. We can do this by using a [countplot](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot) in seaborn.\n",
    "\n",
    "**a)** Produce a seaborn [countplot](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot) object that shows the distribution of ham/spam e-mails. Assign it to a variable (e.g. `ax` to emphasise it is a [matplotlib.axes.Axes](http://matplotlib.org/api/axes_api.html#axes) object)\n",
    "  \n",
    "**b)** In the same cell, modify the labels on the x axis (`xticklabels`) to `Ham` and `Spam` (by default they should be set to `0.0` and `1.0`). *Hint: Axes objects have a [`set_xticklabels`](http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.set_xticklabels) method!* \n",
    "  \n",
    "**c)** Finally, again in the same cell, remove the `is_spam` label from the x axis (`xlabel`) since it does not add any information to the graph\n",
    "\n",
    "You may notice `<matplotlib.text.Text at ...memory_location...>` printed by the ipython notebook. This is just because the notebook is inferring how to display the last object in the cell. To explicitly plot the Axes object, use the `matplotlib.pyplot.show()` method at the very end of the cell, i.e. `plt.show()` (we imported the `matplotlib.pyplot` module as `plt` above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.countplot(x='is_spam', data=spambase)\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[0] = 'Ham'\n",
    "labels[1] = 'Spam'\n",
    "ax.set_xticklabels(labels)\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2788, 1813)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = spambase.is_spam.value_counts()\n",
    "ham=vc[0]\n",
    "spam=vc[1]\n",
    "ham, spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6059552271245382"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham/(ham+spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to simplify the problem by transforming our dataset. We will replace all numerical values which represent word frequencies with a binary value representing whether each word was present in a document or not.\n",
    "### Binarization\n",
    "**a)** Crate a new dataframe called `spambase_binary` from `spambase`. *Hint*: Look into the [`copy`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html) method in pandas. *Tip*: Be careful, in python, unless you explictly say not to, assigment is typically just reference e.g.\n",
    "```python\n",
    "i = [1, 3]\n",
    "j = i\n",
    "i[1] = 5\n",
    "print(j)\n",
    "```\n",
    "outputs:\n",
    "```\n",
    "[1, 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_binary = spambase.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Convert all attributes in `spambase_binary` to Boolean values: 1 if the word or character is present in the email, or 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_binary[spambase_binary > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the 5 last observations of the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "4596             1.0                0.0            1.0           0.0   \n",
       "4597             0.0                0.0            0.0           0.0   \n",
       "4598             1.0                0.0            1.0           0.0   \n",
       "4599             1.0                0.0            0.0           0.0   \n",
       "4600             0.0                0.0            1.0           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "4596            0.0             1.0               0.0                 0.0   \n",
       "4597            0.0             0.0               0.0                 0.0   \n",
       "4598            0.0             0.0               0.0                 0.0   \n",
       "4599            1.0             0.0               0.0                 0.0   \n",
       "4600            0.0             0.0               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "4596              0.0             0.0  ...            1.0              0.0   \n",
       "4597              0.0             0.0  ...            1.0              0.0   \n",
       "4598              0.0             0.0  ...            1.0              0.0   \n",
       "4599              0.0             0.0  ...            1.0              0.0   \n",
       "4600              0.0             0.0  ...            1.0              0.0   \n",
       "\n",
       "      word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
       "4596                   0.0          0.0          1.0          0.0   \n",
       "4597                   0.0          0.0          0.0          0.0   \n",
       "4598                   0.0          1.0          1.0          0.0   \n",
       "4599                   0.0          0.0          1.0          0.0   \n",
       "4600                   0.0          0.0          0.0          0.0   \n",
       "\n",
       "      char_freq_!  char_freq_$  char_freq_#  is_spam  \n",
       "4596          0.0          0.0          0.0      0.0  \n",
       "4597          1.0          0.0          0.0      0.0  \n",
       "4598          0.0          0.0          0.0      0.0  \n",
       "4599          0.0          0.0          0.0      0.0  \n",
       "4600          1.0          0.0          0.0      0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase_binary.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Now we want to get a feeling for how the presence or absence of some specific words could affect the outcome (whether an email is classifed as *ham* or *spam*). We will be focusing on three specific words, namely `make`, `internet` and `edu`.\n",
    "\n",
    "### Countplot\n",
    "**a)** Using seaborn, produce one figure with three [countplots](https://seaborn.github.io/generated/seaborn.countplot.html?highlight=countplot#seaborn.countplot), one for each of the frequency variables for the words `make`, `internet` and `edu`. For each variable, the count plot should have two bars: the number of emails containing the word (i.e. the variable = 1), and the number not containing that word. \n",
    "\n",
    "**b)** Repeat the above but split the bars showing the proportion of emails that are spam/ham. *Hint*: This only requires you to use the `hue` input argument to use different colours for the `is_spam` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xu8VXWd//HXW0TRgSEQMOVoYNBFZQI7Xn70GAZtRoweoE1aWimKl6kfmvaYSrPGvGSXyfRn6TRDSYhlqJkDOqipE6GZIigC6jgwinqQUcTwmsTl8/tjfYENHo57wb6u/X4+Hvtx1v6u71rrs85nnfPZ67LXUkRgZmZWrp3qHYCZmTUXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFowlImirpW/WOo5VIekzS6HrHYc1D0mhJHfWOoxZcOMw6EREHRMTsd+onaZmkv61BSNta/mxJp9Vr+daaXDjM6kQZ/w1a0/FGW0Xp0+hXJC2U9IakayTtKel2Sa9JultSn9T3Jkn/K+kVSXMkHbCNefaS9FtJP0z/eHaVdJmkZyW9IOlfJe1W2zUtno17EpIulHSjpGkpZ49Jak99rgP2BW6V9Lqkr6b2wyTdL2m1pEdLD3mlPYRLJf0eeBPYL7VdIun3aRm/kdSvZJpO5yfpUuCvgavS8q+q1e+nlUjaW9LNklZKelrSF1P7bukw8h8lPQ4cvNV0IWlIyfvCHHJ24ai+TwJ/B7wPGAfcDpwP9CP7/X8x9bsdGAoMAB4GfrH1jCTtAdwD/D4ivhjZ/WK+l+Y9HBgCDAQuqOL6tKLxwHTgXcBM4CqAiDgReBYYFxE9I+KfJQ0E/gP4FtAX+DJws6T+JfM7ETgD6AU8k9o+A5xClv9d0nR0Nb+I+DpwL3BmWv6ZVVr/lpX2CG8FHiX72/oocI6kMcA3gfem1xhgQr3irDUXjur7UUS8EBHLyf7IH4yIRyJiDXALMAIgIqZExGup/ULgQ5J6l8xnb+B3wE0R8Q3IDnUApwNfioiXI+I14NvA8bVauRZxX0TMioj1wHXAh7ro+zlgVuq/ISLuAuYBY0v6TI2IxyJiXUSsTW0/i4j/jog/ATeSfRAod35WPQcD/SPi4oj4c0Q8BfyE7G/sU8Cl6W/vOeCH9Qy0lnaudwAt4IWS4T918r6npG7ApcBxQH9gQxrfD3glDX8ceB3415Lp+wO7A/OzGgKAgG4VjN/gf0uG3wR6SNo5ItZ10vc9wHGSxpW0dQd+W/L+uTKW0TPH/Kx63gPsLWl1SVs3sg+Be7NlLp+hRbhwNIbPAEcDfwssA3oDfyQrAhv9BOgDzJJ0VES8AbxEVnwOSHs0Vntb3176OeC6iDg9xzRdeaf5+fbW1fUc8HREDN16hKSngX2Ax1LTvlt1eZPsg91G7wYKcbmuD1U1hl7AGmAV2Yb27W30OxN4ErhN0m4RsYGsoFwhaQBkx8TT8VerjReA/Ure/xwYJ2mMpG6SeqTr+9u2c/7vNL+tl2+VNRd4VdK56WR4N0kHSjqY7JDi1yT1Sfk4a6tpFwCfSdMcBfxNjWOvGheOxjCNbDd3OfA48EBnndLJ8DPIPgXNkNQDOBdYCjwg6VXgbuD9tQjaAPgO8I10xdOX07Huo8kugFhJlquvsJ1/a2XM70rg2HRlT8scY6+VdF5rHNk5p6fJ9vJ/SnZU4CKyv9ungd+Qnf8qdXaadjXwWeDfaxN19ckPcjIzszy8x2FmZrm4cJiZWS4uHGZmlosLh5mZ5VLI73H069cvBg0aVO8wDJg/f/5LEdH/nXuWx7ltDM5rMZWb10IWjkGDBjFv3rx6h2GApIp+m9a5bQzOazGVm1cfqjIzs1xcOMzMLBcXDjMzy6WQ5ziaxdq1a+no6OCtt96qdyg7rEePHrS1tdG9e/d6h1J3zmsxOa+buXDUUUdHB7169WLQoEGU3Ba96UQEq1atoqOjg8GDB9c7nLpzXovJed3Mh6rq6K233mKPPfZo6o0QQBJ77LFHIT6JVYLzWkzO62YuHHXW7BvhRkVZj0opyu+jKOtRKUX5fezoerhwmJlZLi4cZmaWi0+ON6iRI0dy//331zuMpvDhr0yr2Lzmf/+kis2rM85rMbVaXr3H0aBaaSNsJc5rMbVaXl04GlTPnj0BWLFiBaNGjWL48OEceOCB3HvvvZ32X79+PSeffDIHHnggw4YN44orrgBg9OjRnHPOOYwcOZIDDzyQuXPnAjB37lxGjhzJiBEjGDlyJE8++SQAU6dO5ZhjjmHcuHEMHjyYq666issvv5wRI0Zw2GGH8fLLL9dg7YvLeS2mVstr1Q5VSdqH7Fna7wY2AJMj4kpJFwKnkz0/GeD8iJiVpvkacCqwHvhiRNyZ2o8ie7ZyN+CnEfHdasXdaK6//nrGjBnD17/+ddavX8+bb77Zab8FCxawfPlyFi9eDMDq1as3jXvjjTe4//77mTNnDhMnTmTx4sV84AMfYM6cOey8887cfffdnH/++dx8880ALF68mEceeYS33nqLIUOG8L3vfY9HHnmEL33pS0ybNo1zzjmn+itecM5rMbVKXqt5jmMd8I8R8bCkXsB8SXelcVdExGWlnSXtDxwPHADsDdwt6X1p9NXA3wEdwEOSZkbE41WMvWEcfPDBTJw4kbVr13LMMccwfPjwTvvtt99+PPXUU5x11ll8/OMf58gjj9w07oQTTgBg1KhRvPrqq6xevZrXXnuNCRMmsGTJEiSxdu3aTf0PP/xwevXqRa9evejduzfjxo0DYNiwYSxcuLCKa9s6nNdiapW8Vu1QVUSsiIiH0/BrwBPAwC4mORqYHhFrIuJpYClwSHotjYinIuLPwPTUtyWMGjWKOXPmMHDgQE488USmTev8RHCfPn149NFHGT16NFdffTWnnXbapnFbX7MtiX/6p3/i8MMPZ/Hixdx6661bfBlo11133TS80047bXq/0047sW7dukquXstyXoupVfJak3MckgYBI4AHU9OZkhZKmiKpT2obCDxXMllHattW+9bLOEPSPEnzVq5cufXopvXMM88wYMAATj/9dE499VQefvjhTvu99NJLbNiwgU9+8pNccsklW/S74YYbALjvvvvo3bs3vXv35pVXXmHgwOzXOHXq1Kqvx44oYm6dV+e1mfNa9ctxJfUEbgbOiYhXJf0YuASI9PMHwESgs68yBp0Xt3hbQ8RkYDJAe3v728Y3q9mzZ/P973+f7t2707Nnz21+glm+fDmnnHIKGzZsAOA73/nOpnF9+vRh5MiRvPrqq0yZMgWAr371q0yYMIHLL7+cI444ovorsgOKmFvn1Xlt5rwqonr5ktQduA24MyIu72T8IOC2iDgwnRgnIr6Txt0JXJi6XhgRY1L7Fv06097eHs3wNLEnnniCD37wg1VdxujRo7nssstob2+v6nKg8/WRND8iKrbwznLbaN/jcF7za4a/Wed1s6odqlJ2oO4a4InSoiFpr5JunwAWp+GZwPGSdpU0GBgKzAUeAoZKGixpF7IT6DOrFbeZmXWtmoeqPgKcCCyStCC1nQ+cIGk42eGmZcA/AETEY5JuBB4nuyJrUkSsB5B0JnAn2eW4UyLisSrG3fAOPfRQ1qxZs0Xbddddx7Bhw97Wd/bs2TWKynaU81pMRcxr1QpHRNxH5+ctZnUxzaXApZ20z+pqulbz4IMPvnMnazrOazEVMa/+5riZmeXiwmFmZrm4cJiZWS6+rXoDqeRlpVD+paV33HEHZ599NuvXr+e0007jvPPO22L8mjVrOOmkk5g/fz577LEHN9xwA4MGDaporEXmvBZTK+e1ZQpHvZLc6NavX8+kSZO46667aGtr4+CDD2b8+PHsv//+m/pcc8019OnTh6VLlzJ9+nTOPffcTd9utcbkvBZTo+TVh6pa3Ny5cxkyZAj77bcfu+yyC8cffzwzZszYos+MGTOYMGECAMceeyz33HMP1fziqO0457WYGiWvLhwtbvny5eyzzz6b3re1tbF8+fJt9tl5553p3bs3q1atqmmclo/zWkyNkteWOVRlnevsk8jWd+csp481liLktdFuJdMIGiWv3uNocW1tbTz33OabD3d0dLD33ntvs8+6det45ZVX6Nu3b03jtHyc12JqlLy6cLS4gw8+mCVLlvD000/z5z//menTpzN+/Pgt+owfP55rr70WgF/96lccccQRDfXJ1N7OeS2mRsmrD1U1kHrsTu+8885cddVVjBkzhvXr1zNx4kQOOOAALrjgAtrb2xk/fjynnnoqJ554IkOGDKFv375Mnz695nE2M+e1mFo5ry4cxtixYxk7duwWbRdffPGm4R49enDTTTfVOizbQc5rMTVCXn2oyszMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcfDluA3n24rc/g3hH7HvBonfsM3HiRG677TYGDBjA4sWL3zY+Ijj77LOZNWsWu+++O1OnTuWggw6qaJxF57wWUz3yCo2RW+9xtLiTTz6ZO+64Y5vjb7/9dpYsWcKSJUuYPHkyX/jCF2oYnW0v57W4GiG3LhwtbtSoUV3ex2bGjBmcdNJJSOKwww5j9erVrFixooYR2vZwXourEXLrwmFdKuc2ztZ8nNfiqkVuXTisS41+623bPs5rcfm26lZ35dzG2ZqP81pctcitC4d1afz48UybNo2I4IEHHqB3797stdde9Q7LdpDzWly1yK0vx20g5V6OV0knnHACs2fP5qWXXqKtrY2LLrqItWvXAvD5z3+esWPHMmvWLIYMGcLuu+/Oz372s5rH2Oyc12KqR16hMXLrwtHifvnLX3Y5XhJXX311jaKxSnFei6sRcutDVWZmlosLh5mZ5eLCUWedXTrXjIqyHpVSlN9HUdajUory+9jR9XDhqKMePXqwatWqpt8YI4JVq1bRo0ePeofSEJzXYnJeN6vayXFJ+wDTgHcDG4DJEXGlpL7ADcAgYBnwqYj4o7JvqFwJjAXeBE6OiIfTvCYA30iz/lZEXFutuGupra2Njo4OVq5cWe9QdliPHj1oa2urdxgNwXktJud1s2peVbUO+MeIeFhSL2C+pLuAk4F7IuK7ks4DzgPOBT4GDE2vQ4EfA4emQvNNoB2INJ+ZEfHHKsZeE927d2fw4MH1DsMqzHktJud1s6odqoqIFRv3GCLiNeAJYCBwNLBxj+Fa4Jg0fDQwLTIPAO+StBcwBrgrIl5OxeIu4KhqxW1mZl2ryTkOSYOAEcCDwJ4RsQKy4gIMSN0GAs+VTNaR2rbVbmZmdVD1wiGpJ3AzcE5EvNpV107aoov2rZdzhqR5kuYV4RikbebcFpPz2ryqWjgkdScrGr+IiF+n5hfSISjSzxdTewewT8nkbcDzXbRvISImR0R7RLT379+/sitideXcFpPz2ryqVjjSVVLXAE9ExOUlo2YCE9LwBGBGSftJyhwGvJIOZd0JHCmpj6Q+wJGpzczM6qCaV1V9BDgRWCRpQWo7H/gucKOkU4FngePSuFlkl+IuJbsc9xSAiHhZ0iXAQ6nfxRHxchXjNjOzLlStcETEfXR+fgLgo530D2DSNuY1BZhSuejMzGx7+ZvjZmaWiwuHmZnl4sJhZma5uHCYmVkuLhxmZpaLC4eZmeXiwmFmZrm4cJiZWS4uHGZmlosLh5mZ5eLCYWZmubhwmJlZLi4cZmaWiwuHmZnl4sJhZma5VPNBTmZmDeHZi4dVdH77XrCoovNrNt7jMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLpWqFQ9IUSS9KWlzSdqGk5ZIWpNfYknFfk7RU0pOSxpS0H5Xalko6r1rxmplZeaq5xzEVOKqT9isiYnh6zQKQtD9wPHBAmuZfJHWT1A24GvgYsD9wQuprZmZ1UrUnAEbEHEmDyux+NDA9ItYAT0taChySxi2NiKcAJE1PfR+vcLhmZlamepzjOFPSwnQoq09qGwg8V9KnI7Vtq93MzOqkrMIh6Z5y2srwY+C9wHBgBfCDjbPrpG900d5ZjGdImidp3sqVK7cjNKu1crcr57a5OK/F12XhkNRDUl+gn6Q+kvqm1yBg77wLi4gXImJ9RGwAfsLmw1EdwD4lXduA57to72zekyOiPSLa+/fvnzc0q6G825Vz2xyc19bxTuc4/gE4hyzp89m8B/Aq2UnrXCTtFREr0ttPABuvuJoJXC/p8rSsocDctLyhkgYDy8lOoH8m73Kt4VR0u7KG4by2iC4LR0RcCVwp6ayI+FGeGUv6JTCa7NNHB/BNYLSk4WSHm5aRbWhExGOSbiQ76b0OmBQR69N8zgTuBLoBUyLisTxxWOPZke3KGpfz2jrKuqoqIn4kaSQwqHSaiJjWxTQndNJ8TRf9LwUu7aR9FjCrnDituWzPdmWNz3ktvrIKh6TryE5qLwDWp+YAvCHYdvN2VUzOa/GV+z2OdmD/iOj0iiaz7eTtqpic14Ir93sci4F3VzMQa0nerorJeS24cvc4+gGPS5oLrNnYGBHjqxKVtQpvV8XkvBZcuYXjwmoGYS3rwnoHYFVxYb0DsOoq96qq31U7EGs93q6KyXktvnKvqnqNzbf62AXoDrwREX9ZrcCs+LxdFZPzWnzl7nH0Kn0v6Rg23y7EbLt4uyom57X4tuvuuBHx78ARFY7FWpy3q2JyXoun3ENVf1/ydiey67R9jbbtEG9XxeS8Fl+5V1WNKxleR3afqaMrHo21Gm9XxeS8Fly55zhOqXYg1nq8XRWT81p85T7IqU3SLZJelPSCpJsltVU7OCs2b1fF5LwWX7knx39G9syMvcke3XprajPbEd6uisl5LbhyC0f/iPhZRKxLr6mAH9llO8rbVTE5rwVXbuF4SdLnJHVLr88Bq6oZmLUEb1fF5LwWXLmFYyLwKeB/gRXAsYBPgNmO8nZVTM5rwZV7Oe4lwISI+CNAeiD9ZWQbiNn28nZVTM5rwZW7x/FXGzcCgIh4GRhRnZCshXi7KibnteDK3ePYSVKfrT5BlDut2bY03Hb17MXDKjq/fS9YVNH5NYmGy6tVVrnJ/AFwv6Rfkd064FPApVWLylqFt6ticl4Lrtxvjk+TNI/sRmUC/j4iHq9qZA3On0x3nLerYnJei6/s3ceUeCffKsrbVTE5r8W2XbdVNzOz1uXCYWZmubhwmJlZLi4cZmaWiwuHmZnl4sJhZma5uHCYmVkuLhxmZpZL1QqHpCnp0ZGLS9r6SrpL0pL0s09ql6QfSloqaaGkg0qmmZD6L5E0oVrxmplZeaq5xzEVOGqrtvOAeyJiKHBPeg/wMWBoep0B/Bg23Rztm8ChwCHANzcWGzMzq4+qFY6ImAO8vFXz0cC1afha4JiS9mmReQB4l6S9gDHAXRHxcrrT5l28vRiZmVkN1focx54RsQIg/RyQ2gcCz5X060ht22o3M7M6aZST4+qkLbpof/sMpDMkzZM0b+XKlRUNzurLuS0m57V51bpwvJAOQZF+vpjaO4B9Svq1Ac930f42ETE5Itojor1///4VD9zqx7ktJue1edW6cMwENl4ZNQGYUdJ+Urq66jDglXQo607gSEl90knxI1ObmZnVSdUe5yjpl8BooJ+kDrKro74L3CjpVOBZ4LjUfRYwFlgKvAmcAtmziiVdAjyU+l2cnl9sZmZ1UrXCEREnbGPURzvpG8CkbcxnCjClgqGZmdkOaJST42Zm1iRcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHLZud4BWP08e/Gwis5v3wsWVXR+ZtaYXDjMCsYfCKzafKjKzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHJx4TAzs1zqUjgkLZO0SNICSfNSW19Jd0lakn72Se2S9ENJSyUtlHRQPWI2M7NMPfc4Do+I4RHRnt6fB9wTEUOBe9J7gI8BQ9PrDODHNY/UzMw2aaRDVUcD16bha4FjStqnReYB4F2S9qpHgGZmVr/CEcBvJM2XdEZq2zMiVgCknwNS+0DguZJpO1LbFiSdIWmepHkrV66sYuhWa85tMTmvzateheMjEXEQ2WGoSZJGddFXnbTF2xoiJkdEe0S09+/fv1JxWgNwbovJeW1edSkcEfF8+vkicAtwCPDCxkNQ6eeLqXsHsE/J5G3A87WL1szMStW8cEj6C0m9Ng4DRwKLgZnAhNRtAjAjDc8ETkpXVx0GvLLxkJaZmdVePe6Ouydwi6SNy78+Iu6Q9BBwo6RTgWeB41L/WcBYYCnwJnBK7UM2M8vvw1+ZVtH5zf/+SRWd3/aqeeGIiKeAD3XSvgr4aCftAUyqQWhmZlaGRroc18zMmoAf5NRkKrnre0uvis3KzFqI9zjMzCwXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHLx8zjMGoCfs2LNxHscZmaWiwuHmZnl4sJhZma5uHCYmVkuLhxmZpaLC4eZmeXiwmFmZrm4cJiZWS4uHGZmlosLh5mZ5eJbjpiZNYlnLx5WsXnte8Gi7Z7WexxmZpaLC4eZmeXSNIVD0lGSnpS0VNJ59Y7HzKxVNUXhkNQNuBr4GLA/cIKk/esblZlZa2qKwgEcAiyNiKci4s/AdODoOsdkZtaSFBH1juEdSToWOCoiTkvvTwQOjYgzS/qcAZyR3r4feLLKYfUDXqryMqqtFuvwnojovyMzqHFundfyOK/1Ue31KCuvzVI4jgPGbFU4DomIs+oY07yIaK/X8iuhCOtQaUX4nRRhHSqtKL+TRlmPZjlU1QHsU/K+DXi+TrGYmbW0ZikcDwFDJQ2WtAtwPDCzzjGZmbWkpvjmeESsk3QmcCfQDZgSEY/VOazJdV5+JRRhHSqtCL+TIqxDpRXld9IQ69EU5zjMzKxxNMuhKjMzaxAuHGZmlktTnOOoFUl7APekt+8G1gMr0/tD0pcPG5ak9UDpLS+PiYhl2+g7CLgtIg6sfmT15bwWU7PnFZo3ty4cJSJiFTAcQNKFwOsRcVlpH0kiOze0ofYRvqM/RcTwegfRaJzXYipAXqFJc+tDVWWQNETSYkn/CjwM7CNpdcn44yX9NA3vKenXkuZJmivpsHrFneIZJOleSQ+n18hO+hyQYl0gaaGkoan9cyXt/5buGVYYzqvz2mh5TTE1fG5dOMq3P3BNRIwAlnfR74fAP6dvd34K+Gktgkt2SxvMAkm3pLYXgb+LiIOAT6f4tvZ54Mr0yacd6JD0wdT/I6l9PfDZ6q9CzTmvzmu98gpNmlsfqirf/0TEQ2X0+1vg/dkeMgB9JO0WEX+qXmibdLbb2x24StLGDel9nUz3B+DrktqAX0fEEkkfBT4MPJTWZTeyDbponFfntV55hSbNrQtH+d4oGd4AqOR9j5Jh0Vgn5r4EvAB8iGwP862tO0TE9ZIeBD4O3CnpNLL1uDYivlbLYOvAeS2mZs0rNEFufahqO6QTbX+UNFTSTsAnSkbfDUza+CZ9aqin3sCKFPOJZN+834Kk/YCnIuKHZLdy+Suyq1WOlTQg9ekr6T21C7v2nNdiarK8QhPk1oVj+50L3EGWrI6S9knAR9IJq8eB0+sRXIl/ASZIeoBsl/eNTvp8GlgsaQHwAWBaRDwOfAP4jaSFwF3AXjWKuZ6c12JqlrxCE+TWtxwxM7NcvMdhZma5uHCYmVkuLhxmZpaLC4eZmeXiwmFmZrm4cJiZWS4uHBUkabSk27oYv6uku9N9aT5dy9jKJelCSV+udxz10Aj5k7S3pF+V0e/8aiy/k+UMlzS2FstqBI2wDZSrnn+rvuXIDpDULSLW55hkBNC9s9sob8e8bAc1Yv4i4nng2DK6ng98O8+8tzPGjTfRm5VzuqbQiNtAM2jZPQ5JX5X0xTR8haT/TMMflfRzSSdIWqTs9szfK5nudUkXp/vE/B9JR0n6L0n3AX/fxfIGAD8HhqdPK++VtEzSBWna41LbHZLmK7ut8gfStIMl/UHSQ5IukfR6F8sZLel3km6U9N+Svivps8putbxI0ntTv3GSHpT0SPoEtWcn8zpd0u2SdttWbPVS4PwNkrQ4DZ+s7Jbfd0haIumfU/t32XxX1V+ktk5vp93J+i6TdJGy23UvKonxLyRNSTE+IuloSbsAFwOfVgN8wt5aUbeB1P8rqe9CSReVtH9d0pOS7gbeX9I+W1J7Gu4naVnuX2geEdGSL+Aw4KY0fC8wl+yulN9Mr2eB/mR7Zf9J9mQugAA+lYZ7AM8BQ8luMHYj2RO6trXM0aXjgWXAV0ve3wMMTcOHAv+ZhmcCJ6XhSWQPrOlqGavJbjWwK9ktpS9K484G/l8a7sPmOwecBvwgDV8IfBk4My13165ic/4qnr9BwOI0fDLwFNm9i3oAzwD7pHGvl0zzQeBWsk/CkN2y4qSt17ck5rPS8P8FfpqGvw18Lg2/C/hv4C9SDFfV+++1xbaBI4HJKZ6dgNuAUWR3vl0E7A78JbAU+HKaZjbQnob7Acuq+btv5UNV84EPS+oFrCF74Es78Ndkf4SzI2IlQPpUNwr4d7LbHN+c5vEB4OmIWJL6/Rw4I2ccN6RpewIjgZu0+RbPu6afHwE+mYavA75H1x6KiBVpvv8D/Ca1LwIOT8NtwA2S9gJ2AZ4umf5Esvv5HBMRa98htnopcv5K3RMRr6RlPA68h+wfXamubqddur4b/Tr9nM/mT9hHAuO1+Zh5D2DfHHHWQ1G3gSPT65H0vidZYesF3BIRb6blzcwZZ8W0bOFI/xCXAacA9wMLyf6pvpfsk8qHtzHpW7HlccwdvdnXxhuY7QSsjm0/RjLPctaUDG8oeb+BzTn/EXB5RMyUNJpsT2OjxWTHtttX1kRaAAAB30lEQVTICso7xVZzBc9fqdJcrqfzv9mubqe99fqWzrN0fgI+GRFPbjFj6dD8IddGgbcBAd+JiH/bolE6p4t5rGPzqYce2+hTMS17jiOZQ3ZYZg7Zru7ngQXAA8DfpGOF3YATgN91Mv1/AYOVzhukftslIl4FnpZ0HGTPSpb0oTT698DxabhST/TqzeYno03YatwjwD8AMyXt/Q6x1VMr52+tpO5puBK3074TOEvpo7KkEan9NbJPuo2qiNvAncDEtAeDpIEpt3OATyg759gLGFcyzTI2F8pyLq7YIa1eOO4lOxfwh4h4geyBKfemwzxfA34LPAo8HBEztp44It4i2639j3Ry7JkdjOezwKmSHgUeA45O7WcDkyQ9RPYPvxIuJNulvhd4aeuREXEf2R/kf0jq10Vs9dTK+ZsMLJT0i6jM7bQvITs/sFDZyflLUvtvgf3VgCfHk8JtAxHxG+B64A+SFgG/AnpFxMNkh8UWkB1qu7dkssuAL0i6n+wcR1X5tupNSNLrEdGz3nHY9nH+rNm3gVbf4zAzs5y8x1EFkk4h2zUt9fuImNRZ/+1cxjCyqzNKrYmIhj2Z2SycP/M20DUXDjMzy8WHqszMLBcXDjMzy8WFw8zMcnHhMDOzXP4/40Yabm0XxMcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows all plots in one figure\n",
    "fig, ax =plt.subplots(1,3, sharey = True)\n",
    "sns.countplot(x='word_freq_make', data=spambase_binary, ax=ax[0], hue=\"is_spam\")\n",
    "sns.countplot(x='word_freq_internet', data=spambase_binary, ax=ax[1], hue=\"is_spam\")\n",
    "sns.countplot(x='word_freq_edu', data=spambase_binary, ax=ax[2], hue=\"is_spam\")\n",
    "\n",
    "labels = [item.get_text() for item in ax[0].get_xticklabels()]\n",
    "labels[0] = 'True'\n",
    "labels[1] = 'False'\n",
    "ax[0].set_xticklabels(labels)\n",
    "\n",
    "labels = [item.get_text() for item in ax[1].get_xticklabels()]\n",
    "labels[0] = 'True'\n",
    "labels[1] = 'False'\n",
    "ax[1].set_xticklabels(labels)\n",
    "                      \n",
    "labels = [item.get_text() for item in ax[2].get_xticklabels()]\n",
    "labels[0] = 'True'\n",
    "labels[1] = 'False'\n",
    "ax[2].set_xticklabels(labels)\n",
    "\n",
    "ax[0].title.set_text('make')\n",
    "ax[1].title.set_text('internet')\n",
    "ax[2].title.set_text('edu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes classification\n",
    "Given the transformed dataset, we now wish to train a Naïve Bayes classifier to distinguish spam from regular email by fitting a distribution of the number of occurrences of each word for all the spam and non-spam e-mails. Read about the [Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) and the underlying assumption if you are not already familiar with it. In this lab we focus on the [Multinomial Naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes). We will make use of the `MultinomialNB` class in `sklearn`. **Check out the user guide [description](http://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) and [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) to familiarise yourself with this class.**\n",
    "\n",
    "All classifiers in `sklearn` implement a `fit()` and `predict()` [method](https://en.wikipedia.org/wiki/Method_%28computer_programming%29). The first learns the parameters of the model and the latter classifies inputs. For a Naive Bayes classifier, the [`fit()`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.fit) method takes at least two input arguments `X` and `y`, where `X` are the input features and `y` are the labels associated with each example in the training dataset (i.e. targets). \n",
    "\n",
    "As a first step we extract the input features and targets from the DataFrame. To do so, we will use the [`values`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html) property. For the input features we want to select all columns except `is_spam` and for this we may use the [`drop`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) method which discards the specified columns along the given axis. In fact, we can combine these two operations in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "**a)** Create a Pandas DataFrame object `X` containing only the features (i.e. exclude the label `is_spam`). We need to do this as it is the input Scikit-learn objects expect for fitting. *Hint*: make use of the `drop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spambase_binary.copy()\n",
    "X = X.drop(['is_spam'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Create a Pandas Series object `y` that contains only the label from `spambase_binary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spambase_binary.is_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Display the dimensionality (i.e. `shape`) of each of the two arrays. *Hint:* The shape of `X` and `y` should be `(4601, 54)` and `(4601,)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features shape: (4601, 54)\n",
      "Targets shape: (4601,)\n"
     ]
    }
   ],
   "source": [
    "print('Input features shape: {}'.format(X.shape))\n",
    "print('Targets shape: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier\n",
    "\n",
    "To train a Multinomial Naive Bayes classifier, initialise a `MultinomialNB` object and [`fit`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) the classifier using the `X` and `y` arrays extracted in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial = MultinomialNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "We can evaluate the classifier by looking at the classification accuracy, and the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). \n",
    "\n",
    "Scikit-learn model objects have built in scoring methods. The default [`score` method for `MultinomialNB`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.score) estimates the classification accuracy score. Alternatively, you can compute the prediction for the training data and make use of the [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function (that is in fact what the classifier's `score()` method does under the hood).\n",
    "\n",
    "Scikit-learn also has a [`confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) implementation which returns a numpy array (square matrix) of dimensionality `K`, where `K` is the number of classes (2 in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prior | predict | score | confusion | plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Display the log-prior probabilities for each class. *Hint:* use tab-completion to figure out which attribute of the `MultinomialNB` structure you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class log-priors: [-0.50094918 -0.93129074]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Class log-priors: {}'.format(multinomial.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Predict the output of the classifier by using the training data as input. *Hint*: make use of the `predict` method of the `MultinomialNB` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = multinomial.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Compute the classification accuracy on the training data by either using the `accuracy_score` metric or the `score` method of the `MultinomialNB`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924146924581613"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial.score(X, y)\n",
    "# ca = accuracy_score(y, multinomial.predict(X)) # or ca = gnb.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Compute the resulting confusion_matrix by using the builtin scikit-learn class and display the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2412  376]\n",
      " [ 119 1694]]\n"
     ]
    }
   ],
   "source": [
    "confused = confusion_matrix(y, testY)\n",
    "print (confused)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Normalise the produced confusion matrix by the true class and display the result. In other words, the matrix should show you what proportion of `Ham` emails were predicted as `Ham`/`Spam` and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8651363 , 0.1348637 ],\n",
       "       [0.06563707, 0.93436293]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = confused/confused.sum(axis=1)[:, np.newaxis]\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** By making use of the `plot_confusion_matrix` provided below, visualise the normalised confusion matrix. Plot the appropriate labels on both axes by making use of the `classes` input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEWCAYAAACg+rZnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYFNW5x/HvjwHcQAFBQEBFxSSIGlFxiQbjQnDFJdc1uTF6Rb0xejWaGDUuJBqjSYwLRuFq3CJqYoy4IBjjftWAWxAURIKKbCKLG+Iw894/qgZ7hlm6YXq6i/l9eOqZrqrT55yGft45vHXqlCICMzMrb21K3QEzM2uag7WZWQY4WJuZZYCDtZlZBjhYm5llgIO1mVkGOFjbGpO0nqQHJS2V9Oc1qOd4SROas2+lImkvSdNK3Q9be8jzrFsPSccBZwNfBT4GXgUui4hn17De7wE/AvaIiBVr3NEyJymAfhExo9R9sdbDI+tWQtLZwO+By4HuwGbADcCwZqh+c2B6awjU+ZDUttR9sLVQRHhbyzdgI+AT4D8aKbMOSTCfk26/B9ZJz+0NzAZ+DCwA5gI/SM9dCnwBVKZtnARcAtyZU/cWQABt0/0TgJkko/t/A8fnHH825317ABOBpenPPXLOPQn8AngurWcC0LWBz1bT/5/k9P8w4EBgOrAIOD+n/CDgeWBJWvZ6oH167un0s3yaft6jc+r/KTAPuKPmWPqerdI2Bqb7mwILgb1L/d3wlp3NI+vWYXdgXeD+RspcAOwGfB3YgSRgXZhzvgdJ0O9FEpBHSuocEReTjNbviYgOEXFzYx2RtAFwLXBARHQkCciv1lOuC/BwWnZj4HfAw5I2zil2HPADYBOgPXBOI033IPk76AVcBIwGvgvsBOwFXCRpy7RsFXAW0JXk725f4L8BIuKbaZkd0s97T079XUj+lzE8t+GIeJskkP9J0vrAH4FbI+LJRvprVouDdeuwMbAwGk9THA+MiIgFEfEByYj5eznnK9PzlRHxCMmo8iur2Z9qYICk9SJibkRMqafMQcBbEXFHRKyIiDHAm8AhOWX+GBHTI2IZcC/JL5qGVJLk5yuBu0kC8TUR8XHa/hRge4CIeCkiXkjbnQXcBAzO4zNdHBHL0/7UEhGjgbeAF4GeJL8czfLmYN06fAh0bSKXuinwTs7+O+mxlXXUCfafAR0K7UhEfEqSOjgVmCvpYUlfzaM/NX3qlbM/r4D+fBgRVenrmmA6P+f8spr3S9pG0kOS5kn6iOR/Dl0bqRvgg4j4vIkyo4EBwHURsbyJsma1OFi3Ds8Dn5PkaRsyh+S/8DU2S4+tjk+B9XP2e+SejIjxEbE/yQjzTZIg1lR/avr0/mr2qRB/IOlXv4jYEDgfUBPvaXRalaQOJNcBbgYuSdM8ZnlzsG4FImIpSZ52pKTDJK0vqZ2kAyRdmRYbA1woqZukrmn5O1ezyVeBb0raTNJGwM9qTkjqLunQNHe9nCSdUlVPHY8A20g6TlJbSUcD/YGHVrNPhegIfAR8ko76T6tzfj6w5Srvatw1wEsR8V8kufgb17iX1qo4WLcSEfE7kjnWFwIfAO8BpwN/S4v8EpgE/AuYDLycHludth4D7knreonaAbYNyaySOSQzJAaTXryrU8eHwMFp2Q9JZnIcHBELV6dPBTqH5OLlxySj/nvqnL8EuE3SEklHNVWZpGHAUJLUDyT/DgMlHd9sPba1nm+KMTPLAI+szcwywMHazKyZSbpF0gJJrzdwXpKulTRD0r8kDWyqTgdrM7PmdyvJdYqGHAD0S7fhJDOQGuVgbWbWzCLiaZIL6A0ZBtweiReATpJ6NlZn2S44s2z89b7yaavY64S6EzPMYNLcZ5qaB9+kyoUz84457bttdQq1lxUYFRGjCmiuF8mMrBqz02NzG3pD2QZrM7NylQbmQoJzXfX9cmn0l4WDtZkZQHV992YVzWygT85+b5q4Y9g5azMzgKoV+W9rbizwn+mskN2ApRHRYAoEPLI2MwMgorrZ6pI0hmRN866SZgMXA+2SduJGkuUUDgRmkCxC9oOm6nSwNjMDqG6+YB0RxzZxPoAfFlKng7WZGUAzjqyLwcHazAxa+gJjwRyszczAI2szsyyI5pnlUTQO1mZm0KwXGIvBwdrMDJwGMTPLBF9gNDPLAI+szcwywBcYzcwywBcYzczKX4Rz1mZm5c85azOzDHAaxMwsAzyyNjPLgKrKUvegUQ7WZmbgNIiZWSY4DWJmlgEeWZuZZYCDtZlZ+QtfYDQzywDnrM3MMsBpEDOzDPDI2swsAzyyNjPLAI+szcwyYIUfPmBmVv48sjYzywDnrM3MMsAjazOzDPDI2swsAzyyNjPLAM8GMTPLgIhS96BRDtZmZuCctZlZJpR5sG5T6g6YmZWFqM5/a4KkoZKmSZoh6bx6zm8m6QlJr0j6l6QDm6rTI2szM4CqqmapRlIFMBLYH5gNTJQ0NiKm5hS7ELg3Iv4gqT/wCLBFY/U6WJuZQXOmQQYBMyJiJoCku4FhQG6wDmDD9PVGwJymKnWwNjODgoK1pOHA8JxDoyJiVPq6F/BezrnZwK51qrgEmCDpR8AGwH5NtelgbWYGBd0UkwbmUQ2cVn1vqbN/LHBrRPxW0u7AHZIGRDTcCQdrMzMgqpttnvVsoE/Ofm9WTXOcBAwFiIjnJa0LdAUWNFSpZ4OYmUGSBsl3a9xEoJ+kvpLaA8cAY+uUeRfYF0DS14B1gQ8aq9QjazMzaLbZIBGxQtLpwHigArglIqZIGgFMioixwI+B0ZLOIkmRnBDR+C2UDtZmZtCsN8VExCMk0/Fyj12U83oq8I1C6nSwNjODsr+D0cG6xJ6b+g5X/vVpqquDw3fvz4n771zr/NxFH/PzOx/j42XLqY7gjEP2YK9tt+DhidO47R8vryz31pyFjDn3GL7au1tLfwQrgt2/NYhzRpxJm4o2/O2uh7jt+j/VOr/jbjvw4xFnsPXXtuSCUy/l8YefBKBH7+5cdfNltGnThrbt2nLvLfdx3+0PlOATZJAXcrKGVFVX86s/P8mNPzyM7p06cPxv7mHwgC3ZqmeXlWVGT5jIkB37cdRe2/H23EWcftNYxm17Agft8hUO2uUrQBKo/2f0ww7Ua4k2bdrw08vP5odHn8X8uR9w+7jRPD3hOf49fdbKMvNmz+eSMy/ne6cdU+u9C+d/yImHnEblF5Wst/563PPkbTw1/lkWzv+whT9FBnlkbQ15/Z359OnWid5dNwLg2wO34cnJM2sFawGffv4FAJ98vpxuG26wSj3jXprO0J22aZE+W/Ftu+PXeG/W+7z/7lwAJjzwOIO/vWetYD139jwAqutMN1tR+eWazO3XaUebNp7wlbfmm7pXFEUP1pK2J7nnfWVbEfHXYrebBQuWfEqPTh1W7nfv1IHJ78yrVebUA3bltBseYMzTr7HsixXc9MPDVqlnwstv8fuTDy56f61lbNKjG/Pf/3K67YK5HzBgx6/l/f7um27C7++4kj59e3HNiBs8qs5XM80GKZai/tqVdAtwC3AkcEi6NRhVJA2XNEnSpJsfea6YXSsLscpNTSDVvvnp0Zemc+iuX2XCL07k+lMP4cI7JtQaTU2eNY9127dj6003Lnp/rYXUc/9bIenU+XMWcOy+J3DY7sdw8FFD6dK1c7N1bW0W1dV5b6VQ7JH1bhHRP9/CubdwLht/fXn/n6QZdO/UgXlLPlm5P3/JJ6ukOe5/YSo3nHYoADv07cnyFVUs+XQZXTquD8CjL7/F0J36tVynregWzP2A7r02Wbm/Sc9ufDB/YcH1LJz/IW9Pm8WOu+6w8gKkNaLM0yDFTmg9ny7/Z/XYdrPuvPvBEt7/cCmVK6oY//J0Bm/Xt1aZnp078OL02QDMnLeILyqr6NxhPSDJVz72ylsMHeh89dpk6qtv0qdvbzbt05O27doyZNi+PD3+2bzeu0nPbqyzbnsAOm7UgR122Y5Zb79bzO6uPZpxPetiKPbI+jaSgD0PWE7yH7yIiO2L3G4mtK1ow3nfGcxpN4ylurqaYbv1Z+ueG3PDwy/Qf7NN2Hu7LTn7sL0Ycfc/+NMTr4DEpcfvtzJV8tLb79O9U4eVFyht7VBVVcVV51/NdWN+S0VFG8be/TAzp8/ilHNP4o3X3uTpCc/Rf4evctUtl7Fhp47stf8eDD/3RI7e+z/p229z/ufi04kIJHHnjWN4+82Zpf5I2VDmI2s1cYfjmlUuzQDOBiYDK38dRcQ7Tb23NaRBrHB7nXBPqbtgZWjS3GfqW+muIJ9edEzeMWeDEXevcXuFKvbI+t30Pngzs/JWovRGvoodrN+UdBfwIEkaBPDUPTMrQ2WeBil2sF6PJEgPyTkWgIO1mZWVUk3Jy1dRg3VE/KCY9ZuZNZvWPLJOn35wErAtyeLaAETEicVs18ysYGUerIs9z/oOoAfwbeApksfbfFzkNs3MCldVlf9WAsUO1ltHxM+BTyPiNuAgYLsit2lmVrCojry3Uij2BcbK9OcSSQOAeSSLOpmZlZcyT4MUO1iPktQZuJDkgZEdgJ8XuU0zs8K15tkgJDnrI0lG07elx7oXuU0zs8K18pH1A8BS4CVybooxMys7rTxY946IoUVuw8xsjUVVeadBij0b5P8kefaHmZW/6sh/K4GijKwlTSa5rbwt8ANJM/ESqWZWxko1JS9fxUqD+IGAZpYtrTFY57NetZlZWSnvlHXxn25uZpYFsaK8o7WDtZkZeGRtZpYFrfUCo5lZtnhkbWZW/jyyNjPLAo+szczKX6wodQ8a52BtZgZEmY+si702iJlZNlQXsDVB0lBJ0yTNkHReA2WOkjRV0hRJdzVVp0fWZmY038haUgUwEtgfmA1MlDQ2IqbmlOkH/Az4RkQslrRJU/U2GKwlbdjYGyPio3w7b2ZW7poxDTIImBERMwEk3Q0MA6bmlDkZGBkRiwEiYkFTlTY2sp5CsnKeco7V7AewWSG9NzMrZ1GlpgulJA0HhuccGhURo9LXvYD3cs7NBnatU8U2aT3PARXAJRHxaGNtNhisI6JPnv02M8u8QkbWaWAe1cDp+qJ+3UncbYF+wN5Ab+AZSQMiYklDbeZ1gVHSMZLOT1/3lrRTPu8zM8uKqFbeWxNmA7mD3d7AnHrKPBARlRHxb2AaSfBuUJPBWtL1wLeA76WHPgNubOp9ZmZZEtX5b02YCPST1FdSe+AYYGydMn8jiatI6kqSFpnZWKX5zAbZIyIGSnoFICIWpR0wM1trROSfs268nlgh6XRgPEk++paImCJpBDApIsam54ZImgpUAedGxIeN1ZtPsK6U1IY05yJpY8r+xkwzs8I0500xEfEI8EidYxflvA7g7HTLSz7BeiRwH9BN0qXAUcCl+TZgZpYF1QXMBimFJoN1RNwu6SVgv/TQf0TE68XtlplZy8rjwmFJ5XsHYwVQSZIK8S3qZrbWKfdgnc9skAuAMcCmJFNQ7pL0s2J3zMysJUXkv5VCPiPr7wI7RcRnAJIuA14CflXMjpmZtaRyH1nnE6zfqVOuLU3MBzQzy5rmmrpXLI0t5HQ1SY76M2CKpPHp/hDg2ZbpnplZy6jK8GyQmhkfU4CHc46/ULzumJmVRmZH1hFxc0t2xMyslDKfs5a0FXAZ0B9Yt+Z4RGxTxH6ZmbWoUs3yyFc+c6ZvBf5IsuzfAcC9wN1F7JOZWYtrxlX3iiKfYL1+RIwHiIi3I+JC0tWizMzWFlXVbfLeSiGfqXvLJQl4W9KpwPtAk88LMzPLknJPg+QTrM8COgBnkOSuNwJOLGanzMxaWnVWZ4PUiIgX05cf8+UDCMzM1iqZnbon6X5WfW7YShFxRFF6ZGZWAllOg1zfYr2ox5ZH31DK5q1MzXr2mlJ3wdZSmU2DRMTjLdkRM7NSKtUsj3zlu561mdlarcyzIA7WZmaQ4TRIXZLWiYjlxeyMmVmplPtskHyeFDNI0mTgrXR/B0nXFb1nZmYtqLqArRTyyahfCxwMfAgQEa/h283NbC0TKO+tFPJJg7SJiHeSO85XqipSf8zMSmJFmadB8gnW70kaBISkCuBHwPTidsvMrGWVasScr3yC9WkkqZDNgPnA39NjZmZrjVLlovOVz9ogC4BjWqAvZmYlk/mRtaTR1DNfPCKGF6VHZmYlkPmRNUnao8a6wOHAe8XpjplZaVRlfWQdEffk7ku6A3isaD0yMyuBMn9e7mrdbt4X2Ly5O2JmVkrVWR9ZS1rMlznrNsAi4LxidsrMrKVleiGn9NmLO5A8dxGgOqLcl+g2MytcuV9gbPR28zQw3x8RVenmQG1ma6VqKe+tFPJZG+SfkgYWvSdmZiVUVcBWCg0Ga0k1KZI9SQL2NEkvS3pF0sst0z0zs5ZRrfy3pkgamsbMGZIavMYn6TuSQtLOTdXZWM76n8BA4LCmu2Zmlm3NNRskXUNpJLA/MBuYKGlsREytU64jcAbwYj71NhasBRARb69Wj83MMqQZL8gNAmZExEwASXcDw4Cpdcr9ArgSOCefShsL1t0knd3QyYj4XT4NmJllQSE3xUgaDuQuuTEqIkalr3tR+y7v2cCudd6/I9AnIh6StMbBugLoAGU+U9zMrBkUMnUvDcyjGjhdX8xcOXCX1Aa4GjihgCYbDdZzI2JEIZWZmWVVVfMNS2cDfXL2ewNzcvY7AgOAJ9OHuvQAxko6NCImNVRpkzlrM7PWoBlvipkI9JPUl+SGwmOA42pORsRSoGvNvqQngXMaC9TQ+Dzrfdekt2ZmWdJcD8yNiBXA6cB44A3g3oiYImmEpENXt38NjqwjYtHqVmpmljXN+QjGiHgEeKTOsYsaKLt3PnWuzqp7ZmZrnXJfG8TB2syM0t1Gni8HazMz1s6HD5iZrXWcBjEzywAHazOzDCj3xfodrM3McM7azCwTPBvEzCwDqss8EeJgbWaGLzCamWVCeY+rHazNzACPrM3MMmGFynts7WBtZobTIGZmmeA0iJlZBnjqnplZBpR3qHawNjMDnAYxM8uEqjIfWztYm5nhkbWZWSaER9ZmZuXPI2tbxbf23ZMRV/yMiooK7rr9L1z/+/+tdb59+3Zce+MVbP/1bVm8aAmnnHg2s9+dA8DXtt2GK6++hI4dO1BdXc0B+xzF8uVf0K5dOy6/6gJ233MQUV3NFb+8hofHPlaKj2fN4NlXpvLrW/5CdXU1R+y7BycdMaTW+TkLFnHRDXeyeOknbNRxfS4/8/v02LgzcxYs4qyrRlNdXc2KFVUce+Bgjvr2XiX6FNniqXtWS5s2bbj8Nxdy9GH/xdw58xn3xD1MGPcE06e9vbLMsd87kqVLPmKPgUMZdsQBXHjJjzn1xB9TUVHB9aN+zY9OOY+pr0+jc+eNqKxcAcCZ55zCwg8WsefOByKJzp03KtVHtDVUVVXN5aPvZdRFp9N9404c+9Or2HuX7diqT8+VZX57+/0cMngQw761Gy9Onsa1d47l8jO/T7fOG3LH5WfTvl07Plu2nCPOuoy9d9mOTbp0KuEnyobyDtXQptQdaG123Gk7Zs18l3ffmU1lZSUP3DeObx+4T60yQw/ch3vH/A2Ahx6YwF6DdwNg8D7f4I3XpzP19WkALF68lOrq5D9vxxx/ONdePRqAiGDRoiUt9ZGsmb0+Yxab9ehK7x5dadeuLUP3HMgTE/9Vq8zM9+ay6/ZfAWDQgG14YuJkANq1a0v7du0A+GJFJdVR7iGofKwg8t5KwcG6hfXo2Z3335+3cn/unHn06LnJKmXmpGWqqqr46KOP6dKlE1ttvTlBMOa+UUx46i/89xknArDhRh0B+OkFP2LCU39h1K1X07Xbxi30iay5zV+0lO5dO6/c796lMws+XFqrzDZb9OLvz78KwOMvvsanyz5nycefADBv4WKOPOtyhgz/OScetp9H1XmKAv6UQlGDtaQKSYdKOkPS2TVbI+WHS5okadJnXywuZtdKRlr1QW91/+nrLRNBRUVbBu02kB+e/BOGDf0uBxy8H3t+czfaVlTQq3dPJr74CkMGf4eXJr7Kxb88t0ifwIquntFw3a/Ej79/OC9NncFR51zBpCkz2KRLJyraVADQo2tn7rv6fB4aeTFjn/wnHy75qCV6nXnVBWylUOyR9YPACcDGQMecrV4RMSoido6Inddv37mhYpk2d848evXqsXK/56Y9mD93wSplNk3LVFRUsOGGHVm8eClz58zj+ecmsmjREpYt+5x/PPY02+3Qn0WLlvDZp5/xyIN/B+DBv41nu+37t9yHsmbVfeNOzF/45WBl/qLFdOtS+xrEJl06cfVPTube35zHGccdAkDHDdZbpcxWfXrw0htvY01r1SNroHdEHBERF0fEpTVbkdssa6++/Dp9t9qcPpv3ol27dgw78gDGj3uiVpnx457gqGMPA+DgYUN49ukXAXjy8efov+1XWG+9damoqGC3b+zC9GkzAJjw6JPssdcgAPYcvFutC5aWLdtuvTnvzP2A2fMXUlm5gkeffZm9d96+VpnFH32y8nrF//51PIfvk1zXmPfhYj5f/gUAH33yGa++OZMtNq2dZrP6lfvIutizQcZJGhIRE4rcTmZUVVVx/rmXMea+0VRUtOHuO+9n+pszOPf803ntlSlMGPcEY+64j+tu+jX/9/KjLFm8hFNPPAeApUs/4qaRtzHuH/cSETz+2NM8PuFpAC675Hdcd9MVjPjVeXy4cDFn/fCCUn5MWwNtKyo4/7+O4rRfjKSqOjhsn93YerOejBzzEP233oxv7bI9E6e8xbV3jkWCgf235oKTjwLg37Pn8Ztb70cSEcH3D92XbTbvVeJPlA1VZX4xVlHEDko6HLiTZARfCQiIiNiwqff27NS/vP/mrCRmPXtNqbtgZWidAfuveqGnQMdtfnjeMeeud+5f4/YKVeyR9W+B3YHJUczfCmZma6i1327+FvC6A7WZlbvWfrv5XOBJSeOA5TUHI+J3RW7XzKwg5X67ebFng/wbeBxoTx5T98zMSqU5p+5JGippmqQZks6r5/zZkqZK+pekxyVt3lSdRR1Zt/ZpemaWHc01G0RSBTAS2B+YDUyUNDYipuYUewXYOSI+k3QacCVwdGP1FjVYS+oG/ATYFli35nhE7NPgm8zMSqAZ0yCDgBkRMRNA0t3AMGBlsI6I3JsrXgC+21SlxU6D/Al4E+gLXArMAiYWuU0zs4IVclNM7tIY6TY8p6pewHs5+7PTYw05CRjXVP+KfYFx44i4WdKZEfEU8JSkp4rcpplZwQqZuhcRo4BRDZyubw52vZVL+i6wMzC4qTaLHawr059zJR0EzAF6F7lNM7OCNWMaZDbQJ2e/N0nsq0XSfsAFwOCIWF73fF3FDta/lLQR8GPgOmBD4Kwit2lmVrBmvB1kItBPUl/gfeAY4LjcApJ2BG4ChkbEglWrWFWxZ4M8lL5cCnyrmG2Zma2JqmYaWUfECkmnA+OBCuCWiJgiaQQwKSLGAlcBHYA/p0sivxsRhzZWb7Fng2wJXENyy3k18DxwVs1VUjOzctGcN8VExCPAI3WOXZTzer9C6yz2bJC7gHuBHsCmwJ+BMUVu08ysYBGR91YKxQ7Wiog7ImJFut1J+T+X0sxaoWoi760Uin2B8Yn0Vsu7SYL00cDDkroARMSiIrdvZpaX1r7qXs3tk6fw5YhawInp/pZFbt/MLC/l/vCBYqdBfgrsEBF9gT8CrwFHRkTfiHCgNrOyUe5pkGIH6wsj4iNJe5IsanIr8Icit2lmVrDWHqyr0p8HATdGxAMky6WamZWVcp8NUuyc9fuSbgL2A34taR2K/wvCzKxgrf3hA0eR3MUzNCKWAF2Ac4vcpplZwZrz4QPFUOzbzT8D/pqzP5fkUV9mZmWlKsr7KYzFToOYmWVCuT/X28HazIzyz1k7WJuZ4TsYzcwyodppEDOz8ueRtZlZBng2iJlZBjgNYmaWAU6DmJllgEfWZmYZ4JG1mVkGVEVV04VKyMHazAzfbm5mlgm+3dzMLAM8sjYzywDPBjEzywDPBjEzywDfbm5mlgHOWZuZZYBz1mZmGeCRtZlZBnietZlZBnhkbWaWAZ4NYmaWAb7AaGaWAeWeBmlT6g6YmZWDKOBPUyQNlTRN0gxJ59Vzfh1J96TnX5S0RVN1OlibmZGMrPPdGiOpAhgJHAD0B46V1L9OsZOAxRGxNXA18Oum+udgbWZGkrPOd2vCIGBGRMyMiC+Au4FhdcoMA25LX/8F2FeSGqu0bHPWc5dMbbTjrYmk4RExqtT9sPLi70XzWvHF+3nHHEnDgeE5h0bl/Fv0At7LOTcb2LVOFSvLRMQKSUuBjYGFDbXpkXU2DG+6iLVC/l6USESMioidc7bcX5r1Bf26w/F8ytTiYG1m1rxmA31y9nsDcxoqI6ktsBGwqLFKHazNzJrXRKCfpL6S2gPHAGPrlBkLfD99/R3gH9HElcuyzVlbLc5LWn38vShDaQ76dGA8UAHcEhFTJI0AJkXEWOBm4A5JM0hG1Mc0Va/KfSK4mZk5DWJmlgkO1mZmGeBgXUKStpD0eqn7YWblz8HazCwDHKxLr0LSaElTJE2QtJ6kkyVNlPSapPskrQ8g6VZJf5D0hKSZkgZLukXSG5JuLfHnsDUgaQNJD6f/5q9LOlrSLEm/lvTPdNs6LXtIuvjPK5L+Lql7evwSSbel36NZko6QdKWkyZIeldSutJ/S1oSDden1A0ZGxLbAEuBI4K8RsUtE7AC8QbLoS43OwD7AWcCDJIvAbAtsJ+nrLdpza05DgTkRsUNEDAAeTY9/FBGDgOuB36fHngV2i4gdSdad+ElOPVsBB5GsPXEn8EREbAcsS49bRjlYl96/I+LV9PVLwBbAAEnPSJoMHE8SjGs8mE6enwzMj4jJEVENTEnfa9k0GdgvHUnvFRFL0+Njcn7unr7uDYxPvx/nUvv7MS4iKtP6Kvgy6E/G349Mc7AuveU5r6tIblS6FTg9HRFdCqxbT/nqOu+txjc5ZVZETAd2Igmqv5J0Uc2p3GLpz+uA69PvxynU8/1If4FX5twV5+9HxjlYl6eOwNw0x3h8qTtjxSdpU+CziLgT+A0wMD11dM7P59PXGwFmgloqAAADa0lEQVTvp6+/j7UK/k1bnn4OvAi8QzLS6lja7lgL2A64SlI1UAmcRrLO8TqSXiQZWB2blr0E+LOk94EXgL4t311rab7d3KxMSZoF7BwRDa5xbK2H0yBmZhngkbWZWQZ4ZG1mlgEO1mZmGeBgbWaWAQ7W1ihJVZJeTder+HPNOiWrWdfekh5KXx8q6bxGynaS9N+r0cYlks7J93idMrdK+k4BbXnVRGsxDtbWlGUR8fV0vYovgFNzTypR8PcoIsZGxBWNFOkEFByszdZWDtZWiGeArdMR5RuSbgBeBvpIGiLpeUkvpyPwDgCShkp6U9KzwBE1FUk6QdL16evuku5PV5x7TdIewBXAVumo/qq03LnpaoT/knRpTl0XSJom6e/AV5r6EA2tapjaL12XZbqkg9PyFZKuymn7lDX9izQrlIO15UVSW+AAkjsqIQmKt6crv30KXAjsFxEDgUnA2ZLWBUYDhwB7AT0aqP5a4Kl0lcGBJItSnQe8nY7qz5U0hGSFwkHA14GdJH1T0k4kDxvdkeSXwS55fJzGVjXcAhhMskLdjelnOAlYGhG7pPWfLMl3DVqL8u3m1pT1JNWsCvgMyVOZNwXeiYgX0uO7Af2B5yQBtCdZx+KrJKsKvgUg6U5geD1t7AP8J0BEVAFLJXWuU2ZIur2S7ncgCd4dgfsj4rO0jbF5fKYBkn5JkmrpQPIU6hr3posgvSVpZvoZhgDb5+SzN0rbnp5HW2bNwsHamrIsImqtk50G5E9zDwGPRcSxdcp9ndqrxq0JAb+KiJvqtPE/q9HGrcBhEfGapBOAvXPO1a0r0rZ/FBG5QR1JWxTYrtlqcxrEmsMLwDdynmSyvqRtgDeBvpK2Sssd28D7HydZuKgmP7wh8DG1F7AaD5yYkwvvJWkT4GngcCVP2OlIknJpSmOrGv6HpDZpn7cEpqVtn1bzpBVJ20jaII92zJqNR9a2xiLig3SEOkbSOunhCyNiuqThwMOSFpI84WRAPVWcCYySdBLJmt6nRcTzkp5Lp8aNS/PWXwOeT0f2nwDfjYiXJd0DvEqySuEzeXS5sVUNpwFPAd2BUyPic0n/S5LLfllJ4x8Ah+X3t2PWPLw2iJlZBjgNYmaWAQ7WZmYZ4GBtZpYBDtZmZhngYG1mlgEO1mZmGeBgbWaWAf8PIeuc0vd10UoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "classes = ['ham', 'spam']\n",
    "plot_confusion_matrix(norm, classes=classes, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log probabilities of the features\n",
    "The empirical log probability of input features given a class $P\\left(x_i  |  y\\right)$ is given by the attribute `feature_log_prob` of the classifier. For each feature there are two such conditional probabilities, one for each class. \n",
    "\n",
    "**a)** What dimensionality do you expect the `feature_log_prob_` array to have? Why?\n",
    "\n",
    "*Would expect the array to have 2x54 dimensionality, because we have 54 features of which each can predict one of two classes.*\n",
    "\n",
    "**b)** Inspect the log probabilities of the features. Verify that it has the expected dimensionality (i.e. `shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 54)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the array for feature log probs. Shape (2, 54), because two classes and 54 features.\n",
    "logProbs = multinomial.feature_log_prob_\n",
    "logProbs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Create a list of the names of the features that have higher log probability when the email is `Ham` than `Spam` i.e. what features imply an email is more likely to be `Ham`? *Hint:* There are a many ways to do this. Try it on your own then, if you get stuck, you can do it using index numbers (look up [`np.argwhere`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html)), or using a boolean mask (look up [pandas indexing](http://pandas.pydata.org/pandas-docs/stable/indexing.html)). The column names of a Pandas DataFrame are contained in the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_freq_will', 'word_freq_you', 'word_freq_hp', 'word_freq_hpl',\n",
       "       'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',\n",
       "       'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415',\n",
       "       'word_freq_85', 'word_freq_technology', 'word_freq_1999',\n",
       "       'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs',\n",
       "       'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
       "       'word_freq_re', 'word_freq_edu', 'word_freq_table',\n",
       "       'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_['],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" SOLUTION:\n",
    "feature_names = X.columns\n",
    "hammy_bool = mnb.feature_log_prob_[0] > mnb.feature_log_prob_[1]\n",
    "\n",
    "## Simple boolean selection\n",
    "ham_features = feature_names[hammy_bool].tolist()\n",
    "print(ham_features)\n",
    "\n",
    "## With np.argwhere\n",
    "idx1 = np.argwhere(hammy_bool).squeeze().tolist()\n",
    "print(feature_names[idx1].tolist())\n",
    "\n",
    "## with list comprehension \n",
    "idx2 = [ii for ii, x in enumerate(hammy_bool) if x]\n",
    "print(feature_names[idx2].tolist())\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Finds the indexes of entries where (log prob (ham > spam)) and choses the columns names accordingly.\n",
    "spambase_binary.columns[np.where(logProbs[0,]>logProbs[1,])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final part of this section we will now pretend we are spammers wishing to fool a spam checking system based on Naïve Bayes into classifying a spam e-mail as ham (i.e. a valid e-mail). For this we will use a test set consisting of just one data point (i.e. e-mail). This tiny dataset is called `spambase_test` and has already been pre-processed for you which means that the redundant attributes have been removed and word frequencies have been replaced by word presence/absence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Load `./datasets/spambase_test.csv` dataset into a new pandas structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(os.getcwd(), 'data', 'spambase_test.csv')\n",
    "spambase_test = pd.read_csv(data_path, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use `spambase_test` to create a pandas DataFrame object X_test, contatining the test features, and pandas Series object y_test, containing the test outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54) (1,)\n"
     ]
    }
   ],
   "source": [
    "X_test = spambase_test.drop(['is_spam'], axis=1)\n",
    "y_test = spambase_test['is_spam']\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Feed the input features into the classifier and compare the outcome to the true label. Make sure you don't feed the target into the classifier as you will receive an error (why?). Does the classifer classify the spam e-mail correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(y_test))\n",
    "multinomial.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Pick one (perhaps random) attribute that has higher probability for the ham class (using your feature names in Question 10c) and set the corresponding value in `X_test` to 1. Now predict the new outcome. Has it changed? If not, keep modifying more attributes until you have achieved the desired outcome (i.e. model classifies the e-mail as ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = spambase_binary.columns[np.where(logProbs[0,]>logProbs[1,])]\n",
    "#for value in myList: X_test[value] = 1\n",
    "prediction = multinomial.predict(X_test)\n",
    "print('Actual label: {}\\t Prediction: {}'.format(int(y_test), int(prediction)))\n",
    "\n",
    "\"\"\"\n",
    "#3. Loop until prediction is ham\n",
    "for feat_name in ham_features:\n",
    "    # Multiple indexing methods are available for Pandas\n",
    "#     X_test.iloc[0][feat_name] = 1\n",
    "#     X_test.loc[0][feat_name] = 1\n",
    "    X_test.ix[0, feat_name] = 1\n",
    "    prediction = mnb.predict(X_test)\n",
    "    if prediction != y_test.iloc[0]:\n",
    "        print('The word \"', feat_name[10:], '\" did the trick!')\n",
    "        break\n",
    "        \n",
    "\"\"\"\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
