{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking Breakdown\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "This assignment is based on the automobile pricing dataset. Our goal will be to predict the price of automobiles based on various attributes. This data set consists of three types of entities: \n",
    "\n",
    "1. The specification of an automobile in terms of various characteristics \n",
    "\n",
    "1. Assigned insurance risk rating \n",
    "   * this rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuaries call this process ”symboling”. A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. \n",
    "\n",
    "1. Normalized losses in use as compared to other cars\n",
    "  * the third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year (avg_loss/car/year). \n",
    "\n",
    "\n",
    "To save you time and to make the problem manageable with limited computational resources, we preprocessed the original dataset. We removed any instances that had one or more missing values and randomized the data set. The resulting representation is much more compact and can be used directly to perform our experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression [50%]\n",
    "We will begin by studying a simple Linear Regression model. Such a model will consider the relationship between a dependent (response) variable and only one independent (explanatory) variable. When applying machine learning in practice it can be prudent to start out simple in order to get a feeling for the dataset and for any potential difficulties that might warrant a more sophisticated model. In this Section we will consider one independent variable (i.e. feature) `engine-power` against the dependent variable (i.e. target) `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 --- [1 mark] ==========\n",
    "Load the dataset `train_auto_numeric.csv` into a pandas DataFrame called `auto_numeric`. Display the number of data points and attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data', 'train_auto_numeric.csv')\n",
    "auto_numeric = pd.read_csv(data_path, delimiter = ',')\n",
    "print('Number of data points: {}, number of attributes: {}'.format(auto_numeric.shape[0], auto_numeric.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 --- [1 mark] ==========\n",
    "Display the first 8 instances of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_numeric.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 --- [1 mark] ==========\n",
    "Display the summary statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_numeric.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 --- [2 marks] ==========\n",
    "Produce a scatter plot of `price` against `engine-power`. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_jitter(arr1, arr2, jitter=0.1):\n",
    "    \"\"\" Plots a joint scatter plot of two arrays by adding small noise to each example. \n",
    "    Noise is proportional to variance in each dimension. \"\"\"\n",
    "    arr1 = np.asarray(arr1)\n",
    "    arr2 = np.asarray(arr2)\n",
    "    arr1 = arr1 + jitter*arr1.std(axis=0)*np.random.standard_normal(arr1.shape)\n",
    "    arr2 = arr2 + jitter*arr2.std(axis=0)*np.random.standard_normal(arr2.shape)\n",
    "    plt.scatter(arr1, arr2, c='g', alpha=0.5)\n",
    "\n",
    "scatter_jitter(auto_numeric[\"engine-power\"], auto_numeric[\"price\"])\n",
    "plt.xlabel(\"Engine power\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"Price vs. Engine power\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 --- [2 marks] ==========\n",
    "Do you think that engine-power alone is sufficient for predicting the price? Can you make any other observations on the data from the above plot? Please explain your answer in 2-3 sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I don't think that engine-power alone is sufficient, as it is not enough correlated with the price. There are quite a few data points where the engine power is high and the price low, or vice versa. However, some of such examples are also very far away from the other data points, could be possibly considered to be outliers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 --- [2 marks] ==========\n",
    "Visualise the distribution of the car prices. Choose a sensible value for the number of bins in the histogram. Again, label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(auto_numeric[\"price\"], 15, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Price')\n",
    "plt.grid(True) # Enables grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 --- [2 marks] ==========\n",
    "How could you preprocess the data to improve the performance of linear regression? Don’t do it at this stage, but instead in one sentence explain why you would do what you suggested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We may check scale the features, and/or remove the outliers if there are any (some outliers might be simply very expensive cars).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 --- [1 mark] ==========\n",
    "Now we want to build a simple linear regression model. First we need to define our input and target variables. Store the values of the attribute `engine-power` in a vector `X` and the values of our target variable `price` in a vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(auto_numeric[\"engine-power\"])\n",
    "y = np.array(auto_numeric[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.9 --- [1 mark] ==========\n",
    "For technical reasons, we need to convert `X` into a 2D array, otherwise we will receive an error when trying to use it for building models. Perform this transformation and confirm that the shape of the resulting array is (`n`,1) where `n` is the number of instances in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.size, 1))\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.10 --- [1 mark] ==========\n",
    "Now we want to use Hold-out validation to split the dataset into training and testing subsets. Use 80% of the data for training and the remaining 20% for testing. Store your data into matrices `X_train`, `X_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.11 --- [2 marks] ==========\n",
    "By using Scikit-learn's [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) fit a model to the training data. When initialising the model, set the `normalize` parameter to `True` and use default settings for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(normalize=True).fit(X_train, y_train)\n",
    "regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.12 --- [2 marks] ==========\n",
    "By looking into the attributes of your model, write down an equation for predicting the price of a car given the engine-power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: ', regressor.coef_)\n",
    "print('Intercept: ', regressor.intercept_)\n",
    "\n",
    "def car_price(model, engine_power): \n",
    "    return (model.coef_ * engine_power + model.intercept)\n",
    "\n",
    "# The equation is of form y = ax + b, where a is the coefficient, and b the intercept, thus:\n",
    "# car price = 0.08988389 * engine power + 2823.1218911    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.13 --- [3 marks] ==========\n",
    "What happens to the price as one more unit of engine-power is added? By examining the magnitude of the regression coefficient is it possible to tell whether or not engine-power is an important influential variable on price? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If one more unit of engine-power is added, the price goes up by 0.08988389. The magnitude of the regression coefficient is small, which may imply that engine-power is not a very influential variable on price, but this may not necessarily be truth, as engine-power has a very large std (30k) so this small coefficient gets multiplied with very large values and then added to the price.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.14 --- [2 marks] ==========\n",
    "Produce a scatter plot similar to the one in Question 1.4 but use training data only this time. Add the regression line to the plot and show the predictions on the training set by using a different marker. Label axes appropriately and add a title to the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "training_predictions = regressor.predict(X_train)\n",
    "scatter_jitter(X_train, y_train, jitter=0)\n",
    "plt.plot(X_train, training_predictions, color='r', linewidth=2)\n",
    "plt.xlabel(\"Engine power\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"Engine power vs. Price\")\n",
    "red_patch = mpatches.Patch(color='red', label='Linear regression model predictions')\n",
    "blue_patch = mpatches.Patch(color='green', label='Training data')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.15 --- [2 marks] ==========\n",
    "So far we have used Hold-out validation. Can you think of a disadvantage of using this method, especially when dealing with small datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The main disadvantage of Hold-out validation is high variance of the model evaluation results. The model is fit and tested only once, thus, it's predictive abilities highly depend on how the dataset was split into training/testing subsets. If the dataset is small, or the variance of variable values is high, it is even more likely that the random split would result in a model that generalizes very poorly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.16 --- [1 mark] ==========\n",
    "Now we want to use k-fold cross-validation to evaluate the performance of the regression model. Famliriase yourself with the sklearn method [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) and make sure you understand the differences between Hold-out and K-fold cross-validation. By using Scikit-learn's [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class construct a 5-fold cross-validation object. Set the `shuffle` parameter to `True` and `random_state` to `0`. Use the object to print the training and validation indices for the `auto_numeric` dataset (hint: see the `split` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "counter = 0\n",
    "for train, test in kf.split(auto_numeric):\n",
    "    counter += 1\n",
    "    print (\"\\nFold number: %s\"%counter)\n",
    "    print (\"Training indices: %s\"%train)\n",
    "    print (\"Validation indices: %s\"%test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.17 --- [3 marks] ==========\n",
    "By making use of the iterator you constructed in the previous question, loop through the 5 folds and display the mean value of the `price` variable for the training instances in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kf.split(auto_numeric): \n",
    "    print (\"The mean value of the price variable in the fold: %s\"%auto_numeric.iloc[train].price.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.18 --- [3 marks] ==========\n",
    "Now initialise a new `LinearRegression` model and fit it by making use of the cross-validation iterator, the `X` and `y` arrays defined above and the [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) function. Display the shape of your prediction and confirm it has the same dimensionality as your `y` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(normalize=True)\n",
    "predictions = cross_val_predict(model, X, y, cv=kf)\n",
    "print (\"y shape: %s\\npredictions shape: %s\"%(y.shape, predictions.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.19 --- [2 marks] ==========\n",
    "Report the Coefficient of Determination (R^2), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC) from the simple linear regression model you build in Question 1.18. *Hint: RMSE is the square root of the Mean Squared Error (MSE). For CC you might find numpy's [`corrcoef`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) function useful.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.20 --- [4 marks] ==========\n",
    "What do the above metrics intend to measure? Relate the values of CC, MAE and RMSE to the observations you made in Question 1.5. Explain your answer in 1-2 short paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *RMSE - the standard deviation of model prediction errors (residuals). The errors are measured in terms of how far the values predicted by the model are from the true values. RMSE tells how the data is spread around the best fit mark.* \n",
    "* *MAE - the mean of all absolute model prediction errors (residuals).*\n",
    "* *CC - measures how related are two variables. Calculated dividing the covariance of the variables by the product of their standard deviations.*\n",
    " \n",
    "*If the dataset is small and/or hold-out validation is used, the training set attribute values are more likely to be not normally distributed and deviating a lot. Consequently, the model will generalize (when testing on new data) poorly, and the RMSE/MAE, will be high. Furthermore, high standard deviations of the variables will affect correlation coefficient, making it lower.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.21 --- [3 marks] ==========\n",
    "Show a histogram of the residuals of the linear regression model (i.e. true - predicted values). Label axes appropriately and add a title to your plot. Does the distribution of residuals look like what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist((y - predictions), 15, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The distribution looks somewhat as expected: most of the residuals fall within a small range nearby 0 (meaning that there were a lot of small errors made by the model), and others are more or less normally distributed around that. There are some extremely high and low values, which must be related to the outlier (the errors are huge, because the outliers have significantly different values from the other data points). Interestingly, much bigger part of the residuals are below 0, implying that the model overestimated (predicted higher than true) the value more often.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.22 --- [2 marks] ==========\n",
    "Load the new dataset `train_auto_base.csv` into a pandas DataFrame `auto_base`. Again by using the `engine-power` attribute as predictor and `price` as target variable build a LinearRegression model on this dataset. Report the R^2, RMSE, MAE and CC metrics for this model by making use of the K-fold CV iterator constructed in Question 1.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data', 'train_auto_base.csv')\n",
    "auto_base = pd.read_csv(data_path, delimiter = ',')\n",
    "\n",
    "X = auto_base[\"engine-power\"].values\n",
    "y = auto_base[\"price\"].values\n",
    "X = X.reshape(X.size, 1)\n",
    "y = y.reshape(y.size, 1)\n",
    "\n",
    "model_new = LinearRegression(normalize=True)\n",
    "predictions = cross_val_predict(model_new, X, y, cv=kf)\n",
    "\n",
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.23 --- [2 marks] ==========\n",
    "Show a scatter plot of predicted vs. true prices and another one of predicted price vs. engine-power. Use a single plot with two subplots. Label axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_scatter(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "\n",
    "# Single plot with two subplots (as requested).\n",
    "auto_base['predictions'] = predictions.flatten().tolist()\n",
    "extra = sns.pairplot(data=auto_base, x_vars=['engine-power', 'price'], y_vars = ['predictions'], height = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.24 --- [3 marks] ==========\n",
    "What is the simplest baseline model for the purposes of regression? Relate your answer to the regression model you have just built as part of this question. Can the predictions of this model be justified given the procedure you followed to train it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The simplest baseline model would be calculating the mean value of the dependent variable for predictions (here, price). The model built above is doing precisely that, because the independent engine-power variable is 1 for every data point, and the model relies only on target price averages for predictions. Given the procedure, model predictions are justified to some extent: it predicts averages, but due to cross-validation there are 5 of them.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.25 --- [2 marks] ==========\n",
    "Why do you think this model performs so poorly? (*Hint: Justify your answer by displaying some statistics about the `auto_base` dataset.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_base.price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The predictions are based on the average of the dependent variable values, though these have a high standard deviation, are not normally distributed, and still include outliers. Consequently, the model errors are big and the performance low.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multivariate Linear Regression [50%]\n",
    "In this Section we will fit a Multivariate Linear Regression model (LinearRegression) to the dataset. In contrast to Part 1, we will now train a model with multiple explanatory variables and ascertain how they affect our ability to predict the retail price of a car. One of our foremost concerns will be to determine exactly which attributes to include in the model and which may be left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 --- [10 marks] ==========\n",
    "Use the original dataset (`auto_numeric`) and a visualisation tool of your choice to examine whether or not any of the other attributes are particularly good at predicting the price. Can you find any? Do any attributes appear useless at predicting the price? Do any attributes exhibit significant correlations? As you answer these questions, list two attributes for each question but do not modify the dataset at this stage. Of the attributes you listed, which ones could you safely remove? Explain in 4-5 sentences. *Hint: you might find seaborn's [`pairplot`](https://seaborn.github.io/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) function useful for this question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in list(auto_numeric)[:-1]: \n",
    "    cc = np.corrcoef(auto_numeric[x], auto_numeric.price)[0,1].round(5)\n",
    "    pl = sns.pairplot(data=auto_numeric, x_vars=x, y_vars = 'price', height=6)\n",
    "    pl.fig.suptitle(f'CC = {cc}', y=0.01)\n",
    "    print (\"Correlation Coefficient between price and %s: %s\"%(x, cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Inspecting the pairplots for all possible combinations of independent/dependent variables, as well as calculating the correlation coefficient between these pairs, allowed to make to following conclusions:*\n",
    "\n",
    "* *`engine-size` seems to be particularly good at predicting the price, since the distribution of the data points in the pairplot seems linear, and the values have a small variance (all data points are somewhat tightly packed). `length` and `width` are also pretty good, showing same effect as engine-size, but in a smaller scale.*\n",
    "\n",
    "* *2 attributes that look most useless are `normalized-losses` and `peak-rpm` (also `mean-effective-pressure`), having pairplots that seem most randomly distributed. What is more, their correlation coefficients with the price are the lowest from all attributes.* \n",
    "\n",
    "* *significant correlations are exhibited by these attribues (from highest to lowest): `engine-size`, `width`, `length`, `engine-power`, `highway-mpg`, `wheel-base`.*\n",
    "\n",
    "* *Of the listed attributes, `normalized-losses` and `peak-rpm` could be safely removed, since the relationship between these attributes and price is non-linear, and they do not exhibit significant correlations with the thing that we want to predict.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 --- [3 marks] ==========\n",
    "We will now make a first attempt at building a Multivariate Linear Regression model using all numeric attributes. Initialise a `LinearRegression` model and predict the output by using 5-fold cross-validation and the `cross_val_predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(auto_numeric.drop(['price'], axis=1))\n",
    "y = np.array(auto_numeric[\"price\"])\n",
    "y = y.reshape(y.size, 1)\n",
    "multivariate = LinearRegression()\n",
    "predictions = cross_val_predict(multivariate, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 --- [2 marks] ==========\n",
    "Display the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (CC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 --- [2 marks] ==========\n",
    " Comment on each metric display above in comparison to what you have obtained for the Simple Linear Regression model in Question 1.19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* RMSE for the multivariate model is more than 20% lower than for the simple model (4797 vs. 6114).\n",
    "* MAE is around 20% lower (3271 vs 3987)\n",
    "* CC between model predictions and true prices is almost twice bigger for the multivariate model (0.735 vs 0.417).\n",
    "\n",
    "*To sum up, the multivariate model made smaller and less deviating errors, and the predictions made by it were in correlation with the actual data much more than for the simple linear regression model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 --- [2 marks] ==========\n",
    "Examine the histogram for the `engine-size` attribute. Choose a sensible value for the number of bins in the histogram. Label axes appropriately and include a title in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(auto_numeric['engine-size'], 10, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Engine size')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of engine sizes')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 --- [2 marks] ==========\n",
    "Is the distribution expected to cause a problem for regression? Explain your answer in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generally, linear regression does not make any assumptions about the independent variable, so the distribution of it does not really matter so much. However, it can be observed that most of the values in the histogram fall within a very small range (0-20) and there are not that many values above (apart from the outliers). That could imply that the relationship between the IV and DV might be non-linear, causing problems for regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 --- [3 marks] ==========\n",
    "Transform this attribute using an appropriate simple technique from the lectures. Plot the histogram of the transformed attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = np.log(auto_numeric['engine-size'])\n",
    "n, bins, patches = plt.hist(transformed, 10, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Engine size')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of engine sizes')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 --- [3 marks] ==========\n",
    "Now re-build a Linear Regression model on the transformed dataset and report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = auto_numeric.copy(deep=True)\n",
    "transformed['engine-size'] = np.log(transformed['engine-size'])\n",
    "X = np.array(transformed.drop(['price'], axis=1))\n",
    "y = np.array(transformed[\"price\"])\n",
    "y = y.reshape(y.size, 1)\n",
    "\n",
    "model = LinearRegression(normalize=True)\n",
    "predictions = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 --- [3 marks] ==========\n",
    "How has the performance of your model changed? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The errors got smaller, and the correlation coefficient got higher. Transforming the variable made the relationship between it and the dependant variable (price) more linear. Consequently, model predictions were more accurate.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 --- [2 marks] ==========\n",
    "So far we have performed regression with numeric attributes. We will now attempt to integrate nominal (categorical) attributes into our regression model. \n",
    "Load the dataset `train_auto_full.csv` into a pandas DataFrame called `auto_full`. Display the number of samples and attributes in the dataset. Also, display the first 20 instances of the dataset. *Hint: Execute the cell below to change the default for `max_columns` display option in pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data', 'train_auto_full.csv')\n",
    "auto_full = pd.read_csv(data_path, delimiter = ',')\n",
    "print('Number of data points: {}, number of attributes: {}'.format(auto_full.shape[0], auto_full.shape[1]))\n",
    "auto_full.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 --- [3 marks] ==========\n",
    "This dataset contains a mixture of numeric and nominal attributes. Name the variables that you think are categorical. Why can we not use the nominal attributes in their current form for the purposes of regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The categorical variables are: `make`, `fuel-type`, `aspiration`, `num-of-doors`, `body-style`, `drive-wheels`, `engine-location`, `engine-type`, `num-of-cylinders`, `fuel-system`, `symboling`. We can't use nominal attributes in their current form for the purposes of regression, because it requires attributes to have continuous values. Specifically, regression involves arithmetic operations that can't be performed on (non-quantified) nominal variables.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 --- [5 marks] ==========\n",
    "Now we want to convert the categorical variables by using [One-Hot-Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder). Familiarise yourself with the class. One limitation with this module is that it can deal only with categorical attributes in integer format (remember that in our example we have attributes in string format). \n",
    "\n",
    "Copy the `auto_full` dataframe into a new dataframe `auto_full_edit` and transform the categorical variables by using [Label Encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Then transform again the categorical variables by using One-Hot-Encoding. Make sure you don't transform the continuous variables. *Hint: make appropriate use of the `categorical_features` parameter in [`OneHotEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).*\n",
    "\n",
    "Store the transformed attributes into a numpy array `X_enc` and display its dimensionality.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset and list names of columns that have categorical/ordinal attributes.\n",
    "auto_full_edit = auto_full.copy(deep=True)\n",
    "cat_cols = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system', 'symboling']\n",
    "idx = np.array([auto_full_edit.columns.get_loc(col_name) for col_name in cat_cols])\n",
    "\n",
    "# Encoding categorical data as integers:\n",
    "auto_full_edit[cat_cols] = auto_full_edit[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Removing the targets' column (prices), because one-hot encoding procedure will change the ordering of the data and\n",
    "# output a numpy array without the labels (this column will not be necessary for the following calculations anyway). \n",
    "auto_full_edit = auto_full_edit.drop(['price'], axis = 1)\n",
    "\n",
    "# Mask: boolean array of n_features length (True for categorical columns, False otherwise). \n",
    "cat_idx = np.array([auto_full_edit.columns.get_loc(col_name) for col_name in cat_cols])\n",
    "mask = np.zeros(auto_full_edit.shape[1], dtype=bool)\n",
    "mask[cat_idx] = True\n",
    "\n",
    "# One-hot encoding the categorical attributes in the dataset (using a mask).\n",
    "X_enc = OneHotEncoder(categorical_features=mask).fit_transform(auto_full_edit).toarray()\n",
    "print('Dimensions of the X_enc array with transformed attributes and removed \"price\" column: {}'.format(X_enc.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 --- [2 marks] ==========\n",
    "By using the transformed data train a multivariate linear regression model and by using 5-fold cross-validation report the R^2, RMSE, MAE and CC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In multivariate linear regression, the ordering of the attributes matter, and OneHotEncoder\n",
    "# stacks the non-categorical ones to the end of the array. To bring more important features \n",
    "# upfront, X_enc is flipped.\n",
    "X = np.fliplr(X_enc)\n",
    "y = np.array(auto_full[\"price\"])\n",
    "y = y.reshape(y.size, 1)\n",
    "model = LinearRegression()\n",
    "predictions = cross_val_predict(model, X, y, cv=kf)\n",
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ordering matters due to one specific process that you can read about [here](https://stats.stackexchange.com/questions/21022/does-the-order-of-explanatory-variables-matter-when-calculating-their-regression), but it involves some maths so be prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.14 --- [4 marks] ==========\n",
    "How does this more complex model perform with respect to your best performing model from either question 2.3 or 2.8? List one advantage and one disadvantage of using the more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Previous best performing model (2.8):*\n",
    "* *R^2 = 0.560579712061*\n",
    "* *RMSE = 4457.03690216*\n",
    "* *MAE = 3072.22425609*\n",
    "* *CC = 0.7532852297*\n",
    "\n",
    "*The more complex model performed better than the previous one based on all of the evaluation metrics:*\n",
    "* *RMSE and MAE are both almost two times lower (2460.82 and 1701.36, respectively), meaning that the variance of errors this model makes is much smaller.*\n",
    "* *R^2 is about 1.6 times bigger (0.866), suggesting that a big part of the variance in the price is predictable using this set of features.*\n",
    "* *CC is more than 20% higher (0.933), implying that this model predictions correlate much better with the price values than the ones given by the model in question 2.8. What is more, it is high very overall (assuming that the ideal correlation is 1).*\n",
    "\n",
    "*The main disadvantage of this model is its size (the amount of features) and complexity. Ideally, we would want to have a minimum amount of features. What is more, introducing some unimportant features also diminishes the discriminative effects of the important ones, so it would be good to perform some feature engineering and remove unhelpful features.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.15 --- [4 marks] ==========\n",
    "Finally, experiment with tree-based regressors (e.g. [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), [`RandomForestRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)) and report 5-fold cross-validation scores for R^2, RMSE, MAE and CC. Has your performance improved? Explain your answer in 1-2 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "predictions = cross_val_predict(regressor, X, y.ravel(), cv=kf)\n",
    "print (\"Decision Tree Regressor results: \")\n",
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])\n",
    "\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=10)\n",
    "predictions = cross_val_predict(regressor, X, y.ravel(), cv=kf)\n",
    "print (\"\\nRandom Forest Regressor results: \")\n",
    "print (\"Coefficient of Determination: %s\"%r2_score(y, predictions))\n",
    "print (\"Root Mean Squared Error: %s\"%math.sqrt(mean_squared_error(y, predictions)))\n",
    "print (\"Mean Absolute Error: %s\"%mean_absolute_error(y, predictions))\n",
    "print (\"Correlation Coefficient: %s\"%np.corrcoef(y, predictions, rowvar = False)[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neither DecisionTreeRegressor, nor RandomForestRegressor performed better than the best Multivare Linear Regression (however, both are close). The main reason could be the high-dimensionality of the data (huge amount of features), and small amount of the data points. Decision trees and random forest are not efficient in approximating high-dimensional linear relationships, because they use step functions. Their performace gets lower with the amount of features getting close to the amount of the data points. Removing unnecessary features would improve their performance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
